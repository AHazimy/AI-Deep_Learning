{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "crVxeBw7iHc0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-fhfGBYXigtN"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v12GwV1NiiLn",
        "outputId": "8e0bb8ad-bcce-4965-a56d-fb5a7dd88069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading training1600000processednoemoticoncsv.zip to /content\n",
            " 93% 75.0M/80.9M [00:00<00:00, 161MB/s]\n",
            "100% 80.9M/80.9M [00:00<00:00, 149MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d ferno2/training1600000processednoemoticoncsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voQ4liMjiyvA",
        "outputId": "36d5599b-af96-4909-91ab-3145ed3e188d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  training1600000processednoemoticoncsv.zip\n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip training1600000processednoemoticoncsv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkRd9XThg6-7",
        "outputId": "593c660d-5483-474d-a1d4-128f5074f028"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qs3WgKM9hwVL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "rVWO0kfui-WV"
      },
      "outputs": [],
      "source": [
        "# df.head()\n",
        "# df.shape\n",
        "# df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zio6SsqZjwPo",
        "outputId": "1ab468d8-a7cc-486d-e9fe-a5685db16342"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0          0\n",
              "1          0\n",
              "2          0\n",
              "3          0\n",
              "4          0\n",
              "          ..\n",
              "1599995    4\n",
              "1599996    4\n",
              "1599997    4\n",
              "1599998    4\n",
              "1599999    4\n",
              "Name: sentiment_category, Length: 1600000, dtype: category\n",
              "Categories (2, int64): [0, 4]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['sentiment_category'] = df[0].astype('category')\n",
        "df['sentiment_category']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZO1GXKVkJyd",
        "outputId": "7a7f16b0-dfac-47c8-c087-7f55daf23e8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0          0\n",
              "1          0\n",
              "2          0\n",
              "3          0\n",
              "4          0\n",
              "          ..\n",
              "1599995    1\n",
              "1599996    1\n",
              "1599997    1\n",
              "1599998    1\n",
              "1599999    1\n",
              "Name: sentiment, Length: 1600000, dtype: int8"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['sentiment'] = df['sentiment_category'].cat.codes\n",
        "df['sentiment']\n",
        "# print(f\"categ {df['sentiment'].unique()}\")\n",
        "# print(f\"categ {df['sentiment_category'].unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cU9aynCpnlpI"
      },
      "outputs": [],
      "source": [
        "df.sample(20000).to_csv('train.csv', index=None, header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN8BkDFQoaeb"
      },
      "outputs": [],
      "source": [
        "!pip install -U torchtext==0.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ZxeMNfMznzUp"
      },
      "outputs": [],
      "source": [
        "import torchtext\n",
        "from torchtext.legacy import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "70HXaf2XpKpA"
      },
      "outputs": [],
      "source": [
        "LABEL = data.LabelField()\n",
        "TWEET = data.Field(tokenize='spacy', tokenizer_language = 'en_core_web_sm', lower = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxBQ7mnRpWUy",
        "outputId": "a30da3ba-d9e0-4c5f-9d43-cd1232d1f43b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('score', None),\n",
              " ('id', None),\n",
              " ('date', None),\n",
              " ('query', None),\n",
              " ('name', None),\n",
              " ('tweet', <torchtext.legacy.data.field.Field at 0x7f5b9b5a0e10>),\n",
              " ('category', None),\n",
              " ('label', <torchtext.legacy.data.field.LabelField at 0x7f5b9b5a0090>)]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fields = [('score',None), ('id',None), ('date',None), ('query',None), ('name',None), \n",
        "          ('tweet', TWEET),('category',None),('label',LABEL)]\n",
        "fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "_8aLacwGprik"
      },
      "outputs": [],
      "source": [
        "twitterDataset = data.TabularDataset(path='train.csv', format=\"CSV\", fields=fields, skip_header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "jsRPLePVqEe8"
      },
      "outputs": [],
      "source": [
        "(train, validation, test) = twitterDataset.split(split_ratio = [0.8,0.1,0.1], stratified = True, strata_field = 'label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSIm3vRDqYtb",
        "outputId": "6507317e-457e-4ddb-b30d-4a4f2a45c8d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len train 16000\n",
            "len test 2000\n",
            "len valid 2000\n"
          ]
        }
      ],
      "source": [
        "print(f\"len train {len(train)}\\nlen test {len(test)}\\nlen valid {len(validation)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "3U9HtKk9rVFm"
      },
      "outputs": [],
      "source": [
        "vocab_size = 30000\n",
        "TWEET.build_vocab(train, max_size=vocab_size)\n",
        "LABEL.build_vocab(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJIcbWbzrjwr",
        "outputId": "831afe68-63db-4a9d-aef3-fe21e0322743"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('i', 10110),\n",
              " ('!', 8667),\n",
              " ('.', 8002),\n",
              " (' ', 5919),\n",
              " ('to', 5576),\n",
              " ('the', 5181),\n",
              " (',', 4920),\n",
              " ('a', 3846),\n",
              " ('my', 3114),\n",
              " ('you', 3039),\n",
              " ('it', 3026),\n",
              " ('and', 2945)]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TWEET.vocab.freqs.most_common(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "zNUBkkJksIjt"
      },
      "outputs": [],
      "source": [
        "train_dataloader, valid_dataloader, test_dataloader = data.BucketIterator.splits(\n",
        "    (train, validation, test),\n",
        "    batch_size = 16,\n",
        "    device = device,\n",
        "    sort_key = lambda x: len(x.tweet),\n",
        "    sort_within_batch = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "_BXJo-RvsPdV"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "muSL1cVesQ_r"
      },
      "outputs": [],
      "source": [
        "class MyLSTMModel(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding_dim, vocab_size):\n",
        "        super(MyLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.encoder = nn.LSTM(input_size=embedding_dim,\n",
        "        hidden_size=hidden_size, num_layers=1)\n",
        "        self.predictor = nn.Linear(hidden_size, 2)\n",
        "        pass\n",
        "    \n",
        "    def forward(self, seq):\n",
        "        output, (hidden,_) = self.encoder(self.embedding(seq))\n",
        "        preds = self.predictor(hidden.squeeze(0))\n",
        "        return preds\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XV7f-zCshDn",
        "outputId": "ae906761-0592-4c37-e874-baaf5cb865f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MyLSTMModel(\n",
              "  (embedding): Embedding(30000, 300)\n",
              "  (encoder): LSTM(300, 100)\n",
              "  (predictor): Linear(in_features=100, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MyLSTMModel(hidden_size = 100,embedding_dim = 300, vocab_size = vocab_size)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "7Gp2ViemsmTK"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "bDzruVolsrTU"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "9z3pm-3VtEIq"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "K65NawvfstKD"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "def train(epochs, model, optimizer, criterion, train_dataloader, valid_dataloader):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "     \n",
        "        #set training and valid loss to zero\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        \n",
        "        #set model for train\n",
        "        model.train()\n",
        "        \n",
        "        for batch_idx, batch in enumerate(train_dataloader):\n",
        "            \n",
        "            # get the batch; batch is a list of [tweet, label]\n",
        "            tweet, label = batch\n",
        "            \n",
        "            #optimizer set it to zero_grad(), means clear the gradients  \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            #Forward Pass\n",
        "            predict = model(tweet)\n",
        "            \n",
        "            # Find the Loss\n",
        "            loss = criterion(predict, label)\n",
        "            \n",
        "            # Calculate gradients \n",
        "            loss.backward()\n",
        "            \n",
        "            # Update Weights\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Calculate Loss\n",
        "            training_loss += loss.data.item() * tweet.size(0)\n",
        "            \n",
        "        training_loss /= len(train_dataloader)\n",
        " \n",
        "        #set model for evalution\n",
        "        model.eval()\n",
        "        for batch_idx,batch in enumerate(valid_dataloader):\n",
        "            # get the batch; batch is a list of [tweet, label]\n",
        "            tweet, label = batch\n",
        "            \n",
        "            predict = model(tweet)\n",
        "            loss = criterion(predict, label)\n",
        "            valid_loss += loss.data.item() * tweet.size(0)\n",
        " \n",
        "        valid_loss /= len(valid_dataloader)\n",
        "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}'.format(epoch, training_loss, valid_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q2EwuLjtAq2",
        "outputId": "1d9bdbd8-4fa0-4015-eace-85121b35cfa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training Loss: 19.83, Validation Loss: 10.14\n",
            "Epoch: 2, Training Loss: 14.26, Validation Loss: 9.34\n",
            "Epoch: 3, Training Loss: 9.61, Validation Loss: 12.00\n",
            "Epoch: 4, Training Loss: 5.68, Validation Loss: 14.02\n",
            "Epoch: 5, Training Loss: 3.36, Validation Loss: 17.86\n",
            "Epoch: 6, Training Loss: 2.00, Validation Loss: 17.59\n",
            "Epoch: 7, Training Loss: 1.36, Validation Loss: 18.33\n",
            "Epoch: 8, Training Loss: 0.89, Validation Loss: 20.91\n",
            "Epoch: 9, Training Loss: 0.90, Validation Loss: 24.54\n",
            "Epoch: 10, Training Loss: 0.49, Validation Loss: 24.65\n",
            "Epoch: 11, Training Loss: 0.40, Validation Loss: 26.11\n",
            "Epoch: 12, Training Loss: 0.50, Validation Loss: 22.67\n",
            "Epoch: 13, Training Loss: 0.59, Validation Loss: 27.29\n",
            "Epoch: 14, Training Loss: 0.37, Validation Loss: 27.93\n",
            "Epoch: 15, Training Loss: 0.26, Validation Loss: 28.03\n",
            "Epoch: 16, Training Loss: 0.31, Validation Loss: 27.11\n",
            "Epoch: 17, Training Loss: 0.26, Validation Loss: 26.89\n",
            "Epoch: 18, Training Loss: 0.24, Validation Loss: 27.76\n",
            "Epoch: 19, Training Loss: 0.35, Validation Loss: 27.40\n",
            "Epoch: 20, Training Loss: 0.17, Validation Loss: 27.50\n"
          ]
        }
      ],
      "source": [
        "train(epochs, model, optimizer, criterion, train_dataloader, valid_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "P11m6dgiwnlM"
      },
      "outputs": [],
      "source": [
        "def classifyTweet(tweet):\n",
        "    categories = {0: \"Negative\", 1:\"Positive\"}\n",
        "    processed = TWEET.process([TWEET.preprocess(tweet)])\n",
        "    processed = processed.to(device)\n",
        "    \n",
        "    model.eval()\n",
        "    prediction = model(processed)\n",
        "    print(\"Prediction: \",  prediction)\n",
        "    pred_cat = categories[prediction.argmax().item()] \n",
        "    return pred_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xeoAr6l0wrEq",
        "outputId": "79865b90-754b-49a3-cbed-0a124baa2f6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction:  tensor([[ 0.6446, -0.4574]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifyTweet(\"Working out is bad!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "cd01410336eac871259d3b80a05513ec980a4a867ecd6504aa691f760cbecb55"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
